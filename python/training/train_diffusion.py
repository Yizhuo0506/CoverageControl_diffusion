"""
Train a diffusion policy model for multi-agent coverage control.

Usage:
    python train_diffusion.py <learning_params.toml> <world_size>
"""

import os
import pathlib
import sys
from typing import Dict, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from coverage_control import IOUtils
from coverage_control.nn.models.diffusion_policy import DiffusionPolicy, GaussianDiffusion



class DiffusionDataset(Dataset):
    """
    Simple dataset for diffusion policy training.

    It expects the dataset generated by python/data_generation/data_generation.py
    with --split True, i.e.:

        <DataDir>/<append-dir>/
            train/
                local_maps.pt
                obstacle_maps.pt
                comm_maps.pt
                robot_positions.pt
                edge_weights.pt
                actions.pt or normalized_actions.pt
            val/
            test/

    The shapes follow the convention of the LPAC code base:

        - local_maps:      (M, N, H, W)
        - obstacle_maps:   (M, N, H, W)
        - comm_maps:       (M, N, 2, H, W)
        - robot_positions: (M, N, 2)
        - edge_weights:    (M, N, N)
        - actions:         (M, N, 2)

    where:
        M = number of samples
        N = number of robots (world_size)
    """

    def __init__(
        self,
        data_dir: pathlib.Path,
        split: str,
        use_comm_map: bool,
        world_size: int,
    ) -> None:
        super().__init__()
        self.split = split
        self.data_root = pathlib.Path(data_dir) / split
        self.use_comm_map = use_comm_map

        if not self.data_root.exists():
            raise FileNotFoundError(f"Dataset split directory does not exist: {self.data_root}")

        def _load(name: str) -> torch.Tensor:
            path = self.data_root / name
            if not path.exists():
                raise FileNotFoundError(f"Missing tensor file: {path}")
            t = torch.load(path, map_location="cpu")
            if isinstance(t, torch.Tensor) and t.is_sparse:
                t = t.to_dense()
            return t

        # Core tensors
        robot_positions = _load("robot_positions.pt")       # (M, N, 2)
        local_maps = _load("local_maps.pt")                 # (M, N, H, W)
        obstacle_maps = _load("obstacle_maps.pt")           # (M, N, H, W)
        comm_maps = _load("comm_maps.pt")                   # (M, N, 2, H, W)
        edge_weights = _load("edge_weights.pt")             # (M, N, N)

        # Actions: prefer normalized if present
        actions_path = self.data_root / "normalized_actions.pt"
        if actions_path.exists():
            actions = torch.load(actions_path, map_location="cpu")
            if isinstance(actions, torch.Tensor) and actions.is_sparse:
                actions = actions.to_dense()
            self.actions_normalized = True
        else:
            actions = _load("actions.pt")
            self.actions_normalized = False

        if actions.shape != robot_positions.shape:
            raise ValueError(
                f"Actions shape {tuple(actions.shape)} does not match robot positions "
                f"shape {tuple(robot_positions.shape)}"
            )

        M, N, H, W = local_maps.shape
        if N != world_size:
            raise ValueError(
                f"World size mismatch: dataset has {N} robots, expected {world_size}."
            )

        # Build coverage maps: (M, N, C, H, W)
        if use_comm_map:
            C = 4
            coverage_maps = torch.zeros((M, N, C, H, W), dtype=local_maps.dtype)
            coverage_maps[:, :, 0, :, :] = local_maps
            coverage_maps[:, :, 1, :, :] = obstacle_maps
            coverage_maps[:, :, 2:4, :, :] = comm_maps
        else:
            C = 2
            coverage_maps = torch.zeros((M, N, C, H, W), dtype=local_maps.dtype)
            coverage_maps[:, :, 0, :, :] = local_maps
            coverage_maps[:, :, 1, :, :] = obstacle_maps

        self.coverage_maps = coverage_maps      # (M, N, C, H, W)
        self.actions = actions                  # (M, N, 2)
        self.robot_positions = robot_positions  # (M, N, 2)
        self.edge_weights = edge_weights        # (M, N, N)

        self.num_samples = M
        self.world_size = N
        self.map_size = H

    def __len__(self) -> int:
        return self.num_samples

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Returns:
            coverage_maps[idx]:   (N, C, H, W)
            actions[idx]:         (N, 2)
            robot_positions[idx]: (N, 2)
            edge_weights[idx]:    (N, N)
        """
        return (
            self.coverage_maps[idx],
            self.actions[idx],
            self.robot_positions[idx],
            self.edge_weights[idx],
        )




def train_one_epoch(
    model: nn.Module,
    diffusion: GaussianDiffusion,
    data_loader: DataLoader,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
) -> float:
    """
    One training epoch over the diffusion dataset.

    The loss is the MSE between the predicted noise and the true Gaussian noise,
    averaged over random diffusion steps t in [0, T - 1].
    """
    model.train()
    num_steps = diffusion.num_steps

    total_loss = 0.0
    total_samples = 0

    for coverage_maps, targets, robot_positions, edge_weights in data_loader:
        coverage_maps = coverage_maps.to(device)          # (B, N, C, H, W)
        targets = targets.to(device)                      # (B, N, 2)
        robot_positions = robot_positions.to(device)      # (B, N, 2)
        edge_weights = edge_weights.to(device)            # (B, N, N)

        B, N, C, H, W = coverage_maps.shape
        actions_0 = targets                               # Clean actions u_0

        # Sample random diffusion steps for each graph in the batch
        t = torch.randint(0, num_steps, (B,), device=device, dtype=torch.long)  # (B,)

        # Forward diffusion q(u_t | u_0)
        noise = torch.randn_like(actions_0)               # (B, N, 2)
        actions_t = diffusion.q_sample(actions_0, t, noise)

        # Predict noise and compute loss
        optimizer.zero_grad(set_to_none=True)
        eps_hat = model(
            coverage_maps=coverage_maps,
            actions_t=actions_t,
            t=t,
            positions=robot_positions,
            edge_weights=edge_weights,
        )  # (B, N, 2)

        loss = F.mse_loss(eps_hat, noise)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * B
        total_samples += B

    return total_loss / max(total_samples, 1)


@torch.no_grad()
def eval_one_epoch(
    model: nn.Module,
    diffusion: GaussianDiffusion,
    data_loader: DataLoader,
    device: torch.device,
) -> float:
    """
    Evaluate the model on a dataset split using the same noise prediction loss.
    """
    model.eval()
    num_steps = diffusion.num_steps

    total_loss = 0.0
    total_samples = 0

    for coverage_maps, targets, robot_positions, edge_weights in data_loader:
        coverage_maps = coverage_maps.to(device)          # (B, N, C, H, W)
        targets = targets.to(device)                      # (B, N, 2)
        robot_positions = robot_positions.to(device)      # (B, N, 2)
        edge_weights = edge_weights.to(device)            # (B, N, N)

        B, N, C, H, W = coverage_maps.shape
        actions_0 = targets

        t = torch.randint(0, num_steps, (B,), device=device, dtype=torch.long)
        noise = torch.randn_like(actions_0)
        actions_t = diffusion.q_sample(actions_0, t, noise)

        eps_hat = model(
            coverage_maps=coverage_maps,
            actions_t=actions_t,
            t=t,
            positions=robot_positions,
            edge_weights=edge_weights,
        )
        loss = F.mse_loss(eps_hat, noise)

        total_loss += loss.item() * B
        total_samples += B

    return total_loss / max(total_samples, 1)


def main() -> None:
    if len(sys.argv) < 3:
        raise SystemExit(
            "Usage: python train_diffusion.py <learning_params.toml> <world_size>"
        )

    config_file = sys.argv[1]
    world_size = int(sys.argv[2])

    # Load training config (same TOML as train_lpac.py)
    config = IOUtils.load_toml(config_file)

    # Device
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # Dataset root: same convention as train_lpac.py
    dataset_root = pathlib.Path(IOUtils.sanitize_path(config["DataDir"]))
    data_dir = dataset_root / "data"

    num_workers = int(config.get("NumWorkers", 4))
    use_comm_map = bool(config["ModelConfig"]["UseCommMaps"])

    diff_model_cfg: Dict = config["DiffusionModel"]
    diff_train_cfg: Dict = config["DiffusionTraining"]

    batch_size = int(diff_train_cfg["BatchSize"])
    num_epochs = int(diff_train_cfg["NumEpochs"])
    lr = float(diff_train_cfg["LearningRate"])
    weight_decay = float(diff_train_cfg["WeightDecay"])
    num_diff_steps = int(diff_train_cfg["NumDiffusionSteps"])
    beta_start = float(diff_train_cfg.get("BetaStart", 1e-4))
    beta_end = float(diff_train_cfg.get("BetaEnd", 2e-2))

    # Model directory
    model_dir = IOUtils.sanitize_path(diff_model_cfg["Dir"])
    os.makedirs(model_dir, exist_ok=True)
    best_model_path = os.path.join(model_dir, "diffusion_policy_best.pt")

    # Datasets
    train_dataset = DiffusionDataset(data_dir, "train", use_comm_map, world_size)
    val_dataset = DiffusionDataset(data_dir, "val", use_comm_map, world_size)

    print(
        f"Dataset: train | Size: {len(train_dataset)} "
        f"Coverage Maps: {tuple(train_dataset.coverage_maps.shape)} "
        f"Targets: {tuple(train_dataset.actions.shape)} "
        f"Robot Positions: {tuple(train_dataset.robot_positions.shape)} "
        f"Edge Weights: {tuple(train_dataset.edge_weights.shape)}"
    )
    print(
        f"Dataset: val   | Size: {len(val_dataset)} "
        f"Coverage Maps: {tuple(val_dataset.coverage_maps.shape)} "
        f"Targets: {tuple(val_dataset.actions.shape)} "
        f"Robot Positions: {tuple(val_dataset.robot_positions.shape)} "
        f"Edge Weights: {tuple(val_dataset.edge_weights.shape)}"
    )

    # Load action normalization stats if present (for later sampling / sim2real)
    actions_mean_path = data_dir / "actions_mean.pt"
    actions_std_path = data_dir / "actions_std.pt"
    actions_mean = None
    actions_std = None
    if actions_mean_path.exists() and actions_std_path.exists():
        actions_mean = torch.load(actions_mean_path, map_location="cpu")
        actions_std = torch.load(actions_std_path, map_location="cpu")

    # Create model (uses CNNBackBone + DiffusionModel from config)
    model = DiffusionPolicy(config).to(device)

    # If we have pre-computed normalization stats, store them in the model buffers
    if actions_mean is not None and actions_std is not None:
        with torch.no_grad():
            # Make sure the shapes are broadcastable to (B, N, 2)
            model.actions_mean.copy_(actions_mean.to(device))
            model.actions_std.copy_(actions_std.to(device))

    # Data loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )

    # Diffusion process (shared across training / evaluation / controller)
    diffusion = GaussianDiffusion(
        num_steps=num_diff_steps,
        beta_start=beta_start,
        beta_end=beta_end,
        device=device,
    )

    # Optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)

    best_val_loss = float("inf")

    for epoch in range(1, num_epochs + 1):
        train_loss = train_one_epoch(model, diffusion, train_loader, optimizer, device)
        val_loss = eval_one_epoch(model, diffusion, val_loader, device)

        print(
            f"[Epoch {epoch:03d}] train_loss = {train_loss:.6f} | "
            f"val_loss = {val_loss:.6f}"
        )

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            state_dict = model.state_dict()

            torch.save(
                {
                    "model_state_dict": state_dict,
                    "config": diff_model_cfg,
                    "training_cfg": diff_train_cfg,
                    "diffusion": diffusion.to_state_dict(),
                },
                best_model_path,
            )

            print(f"  -> Saved best model to: {best_model_path}")

    # Optional: test set evaluation
    test_dataset = DiffusionDataset(data_dir, "test", use_comm_map, world_size)
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )
    test_loss = eval_one_epoch(model, diffusion, test_loader, device)
    print(f"[Test] loss = {test_loss:.6f}")


if __name__ == "__main__":
    main()
